---
title: "Classical music and Movie Soundtracks"
author: "Emma Bakker"
date: "2023-03-13"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
library(flexdashboard)
library(spotifyr)
library(tidyverse)
library(ggplot2)
library(plotly)
library(tidyr)
library(dplyr)
library(compmus)

Sys.setenv(SPOTIFY_CLIENT_ID = '76f37f6c523d482a8c825d01db224388')
Sys.setenv(SPOTIFY_CLIENT_SECRET = '934add8cf3744afc89d1391370327a5d')

access_token <- get_spotify_access_token()
 

classical_essentials <- get_playlist_audio_features("", "37i9dQZF1DWWEJlAGA9gs0")
iconic_soundtracks <- get_playlist_audio_features("", "37i9dQZF1DX1tz6EDao8it") 
```

Visual Analysis {.storyboard data-icon="fa-signal"}
======================================================

### What are the differences in keygrams between an outlier and a song that is representative of the rest of the playlist

```{r, figures-side, fig.show="hold", out.width="50%"}



par(mar = c(4, 4, .1, .1))

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

brooks_was_here <-
  get_tidy_audio_analysis("5FRGTGPZ7uA6JaLAH55PVV") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

brooks_was_here |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "'Brooks was here' by Thomas Newman", x = "Time (s)", y = "")


end_titles <-
  get_tidy_audio_analysis("1CxT3WZkSuEAxPOKAPzDDl") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

end_titles |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "'End Titles' by Rachel Portman", x = "Time (s)", y = "")


par(mar = c(4, 4, .1, .1))
 
vaughan <-
  get_tidy_audio_analysis("1CDEWKmyRTPWWa7uIKVSU4") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

vaughan |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "'Job, a Masque for Dancing' by Ralph  Vaughan Williams", x = "Time (s)", y = "")


tsar_saltan <-
  get_tidy_audio_analysis("4fDodwdZ1LBDL2I2WCnUMY") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

tsar_saltan |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "'Tsar Saltan, Op. 57: Flight of the Bumblebee' by André Previn", x = "Time (s)", y = "")



```

---

The top two chordograms are two songs from the Iconic Soundtracks playlist, namely "Brooks was here" by Thomas Newman and "End Titles" by Rachel Portman. The chordograms represent the chords used in the songs over time, with the x-axis representing time in seconds and the y-axis representing the different chords. The chords are represented using 1-0 coding for chord templates and the Krumhansl-Kessler key profiles.
The two chordograms show that the two songs have different chord progressions. "Brooks was here" has more varied and complex chords compared to "End Titles", which has a simpler chord progression. The chordogram for "Brooks was here" has more vertical lines, indicating more chord changes, whereas the chordogram for "End Titles" has more horizontal lines, indicating longer sections with the same chord.
Overall, the chordograms provide a visual representation of the harmonic structure of the two songs, highlighting differences in chord progression and complexity.
It is worth noting that "Brooks was here" stands out as an outlier of the Classical Essentials playlist, with a significantly different chord progression compared to the rest of the playlist. "End Titles" serves as a representative example of the typical chord progression in the playlist.

The two chordograms on the bottom are from two songs, 'Tsar Saltan, Op. 57: Flight of the Bumblebee' by André Previn, and 'Job, a Masque for Dancing' by Ralph Vaughan Williams. The chordograms are visual representations of the harmonic structure of the songs, with again time on the x-axis and the chords on the y-axis. The colors of the rectangles represent the strength of each chord based on the Krumhansl-Kessler key profile.
The two chordograms are significantly different. The chordogram of 'Tsar Saltan, Op. 57: Flight of the Bumblebee' has more consistent coloring and clear harmonic patterns. On the other hand, the chordogram of 'Job, a Masque for Dancing' is more complex, with a wider range of colors and less clear harmonic patterns. This difference is due to the fact that 'Tsar Saltan, Op. 57: Flight of the Bumblebee' is a piece from the Classical Essentials playlist and follows traditional harmonic patterns, while 'Job, a Masque for Dancing' is an outlier from the playlist and has more complex and unpredictable harmonic patterns.  

### What are the differences in audio features of a playlist with movie soundtracks of classical songs

```{r}
classical <- get_playlist_audio_features("", "37i9dQZF1DWWEJlAGA9gs0")
soundtracks <- get_playlist_audio_features("", "37i9dQZF1DX1tz6EDao8it")

# add playlist names to the data frames
classical$playlist <- "Classical Essentials"
soundtracks$playlist <- "Iconic Soundtracks"

# combine the playlists into one dataframe
audio_features <- bind_rows(classical, soundtracks)


# create a more colorful color scale based on acousticness
color_scale <- scale_color_gradient(low = "#FEE08B", high = "#D53E4F", guide = guide_colorbar(title = "Acousticness"))

# create scatterplot with geom_jitter() and geom_smooth()
scatter_plot <- ggplot(audio_features, aes(x = energy, y = loudness, color = acousticness, text = track.name)) +
  geom_jitter(alpha = 0.8, size = 2) +
  facet_wrap(~ playlist, scales = "free", labeller = labeller(playlist = c("Classical Essentials" = "Classical Essentials", "Iconic Soundtracks" = "Iconic Soundtracks"))) +
  geom_smooth(aes(group = playlist), method = "lm", se = FALSE, color = "black", alpha = 0.5, size = 1) +
  scale_x_continuous(limits = c(0, 1), expand = c(0, 0)) +
  scale_y_continuous(limits = c(-45, -5), expand = c(0, 0)) +
  color_scale +
  labs(x = "Energy", y = "Loudness", title = "Scatterplot of Energy vs. Loudness for Classical and Soundtrack Playlists", color = "Acousticness") +
  theme_bw() +
  theme(panel.grid.major = element_line(color = "gray90"), panel.grid.minor = element_blank(), panel.border = element_blank(), axis.line = element_line(colour = "black"), strip.text = element_text(size = 14)) 

# convert scatterplot to plotly object for interactivity
scatter_plot <- ggplotly(scatter_plot, tooltip = c("color", "text", "x", "y"), width = 1000, height = 500)

# set plot background to grid
scatter_plot %>% layout(plot_bgcolor = "white", paper_bgcolor = "white", xaxis = list(showgrid = TRUE, gridcolor = "gray90"), yaxis = list(showgrid = TRUE, gridcolor = "gray90"))

# display the plot
scatter_plot

```

---

This graph shows a scatterplot of the energy vs. loudness for two different playlists: "Classical Essentials" and "Iconic Soundtracks". Each point in the scatterplot represents a track, with the color of the point indicating the acousticness of the track. The plot also includes a linear regression line for each playlist, with no standard error shown.

In general, the "Iconic Soundtracks" playlist tends to have tracks with higher energy and higher loudness compared to the "Classical Essentials" playlist, which tends to have tracks with lower energy and lower loudness. However, there is some overlap between the playlists, particularly in the range of energy values around 0.4 and loudness values around -10.

The acousticness of the tracks in each playlist varies widely, with some tracks having very low acousticness values (indicating that they have a more electronic or synthetic sound) and others having very high acousticness values (indicating that they have a more natural or acoustic sound). The color scale used in the plot ranges from yellow (low acousticness) to red (high acousticness).

Overall, this plot provides a useful visual representation of the differences in energy and loudness between these two playlists and how the acousticness of the tracks varies within each playlist.

### Chroma and Timbre values of The Blade Runnner Blues

```{r}

# extract chroma values
get_chroma <- function(track.id) {
  audio_analysis <- get_track_audio_analysis(track.id)
  chroma <- audio_analysis$segments %>%
    select(start, pitches) %>%
    unnest(pitches) %>%
    mutate(pitch_class = rep(c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"), length.out = length(pitches)),
           intensity = as.numeric(pitches)) %>%
    select(-pitches) %>%
    spread(pitch_class, intensity, fill = 0)
  
  return(chroma)
}

get_timbre <- function(track.id) {
  audio_analysis <- get_track_audio_analysis(track.id)
  timbre <- audio_analysis$segments %>%
    select(start, timbre) %>%
    unnest(timbre) %>%
    mutate(timbre_number = rep(1:12, length.out = length(timbre)),
           value = as.numeric(timbre)) %>%
    select(-timbre) %>%
    spread(timbre_number, value, fill = 0)
  
  return(timbre)
}


# get chroma data frames for all tracks in iconic_soundtracks playlist
iconic_soundtracks_chroma <- map(iconic_soundtracks$track.id, get_chroma)

iconic_soundtracks_chroma <- map2(iconic_soundtracks_chroma, iconic_soundtracks$track.id, ~ .x %>% mutate(track_id = .y))

iconic_soundtracks_chroma <- bind_rows(iconic_soundtracks_chroma)

classical_essentials_chroma <- map(classical_essentials$track.id, get_chroma)

classical_essentials_chroma <- map2(classical_essentials_chroma, classical_essentials$track.id, ~ .x %>% mutate(track_id = .y))

classical_essentials_chroma <- bind_rows(classical_essentials_chroma)

# get chroma data frames for all tracks in iconic_soundtracks playlist
iconic_soundtracks_timbre <- map(iconic_soundtracks$track.id, get_timbre)

iconic_soundtracks_timbre <- map2(iconic_soundtracks_timbre, iconic_soundtracks$track.id, ~ .x %>% mutate(track_id = .y))

iconic_soundtracks_timbre <- bind_rows(iconic_soundtracks_timbre)

classical_essentials_timbre <- map(classical_essentials$track.id, get_timbre)

classical_essentials_timbre <- map2(classical_essentials_timbre, classical_essentials$track.id, ~ .x %>% mutate(track_id = .y))

classical_essentials_timbre <- bind_rows(classical_essentials_timbre)


# get chroma and timbre data for the outlier track
outlier_chroma <- get_chroma("575blCgesVtCu0HEYaIcas")
outlier_timbre <- get_timbre("575blCgesVtCu0HEYaIcas")

# create chromagram plot
chromagram <- outlier_chroma %>%
  select(-start) %>%
  as.matrix() %>%
  t() %>%
  round(3) %>%
  plot_ly(
    x = 1:12, y = 0:20, z = .,
    type = "heatmap", colorscale = "Viridis"
  ) %>%
  layout(
    title = "Chromagram for Blade Runner Blues",
    xaxis = list(title = "<b>Pitch Class</b>", tickvals = 1:12, ticktext = c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"), showgrid = FALSE),
    yaxis = list(title = "<b>Time (seconds)</b>", showgrid = FALSE),
    hoverlabel = list(
      bgcolor = "white",
      font = list(size = 12),
      bordercolor = "black"
    )
  )

# create cepstrogram plot
cepstrogram <- outlier_timbre %>%
  select(-start) %>%
  as.matrix() %>%
  t() %>%
  round(3) %>%
  plot_ly(
    x = 1:12, y = 0:20, z = .,
    type = "heatmap", colorscale = "ViridisLite"
  ) %>%
  layout(
    title = "Cepstrogram for Blade Runner Blues",
    xaxis = list(title = "<b>Cepstral Coefficient</b>", showgrid = FALSE),
    yaxis = list(title = "<b>Time (seconds)</b>", showgrid = FALSE),
    hoverlabel = list(
      bgcolor = "white",
      font = list(size = 12),
      bordercolor = "black"
    )
  )


# create combined plot
combined_plot <- subplot(
  chromagram, cepstrogram,
  nrows = 2, margin = 0.05,
  heights = c(0.5, 0.5),
  titleX = FALSE, titleY = FALSE
)

# add description
description <- description <- "<b>Chromagram:</b> The distribution of the 12 pitch classes over time in the selected song.<br><b>Cepstrogram:</b> The distribution of the 12 cepstral coefficients over time, which are related to the timbre of the sound. The combined plot allows for a comparison of the two features, highlighting the rhythmic and tonal characteristics of the song. When hovering over the chromagram plot or cepstrogram plot, the x values show the pitch class or cepstral coefficient, the y value represents the time in seconds and the z value represents the intensity of the pitch class or cepstral coefficient at the given time."

combined_plot <- combined_plot %>% layout(
  title = "Chromagram and Cepstrogram for Blade Runner Blues",
  annotations = list(
    x = 0.5, y = -0.12,
    text = description,
    showarrow = FALSE,
    xref = "paper",
    yref = "paper",
    font = list(size = 12)
  )
)

# display plot
combined_plot

```

---

<b>Chromagram:</b> The distribution of the 12 pitch classes over time in the selected song.<br><b>Cepstrogram:</b> The distribution of the 12 cepstral coefficients over time, which are related to the timbre of the sound. The combined plot allows for a comparison of the two features, highlighting the rhythmic and tonal characteristics of the song. When hovering over the chromagram plot or cepstrogram plot, the x values show the pitch class or cepstral coefficient, the y value represents the time in seconds and the z value represents the intensity of the pitch class or cepstral coefficient at the given time.

Looking at the cepstrogram plot, we can see that the song "Blade Runner Blues" has a relatively smooth and uniform distribution of timbre features over time, with a prominent peak at the lower cepstral coefficients. This suggests a relatively low level of roughness in the sound, which is consistent with the overall mellow and atmospheric mood of the song.

In terms of brightness and warmth, the cepstrogram does not reveal any particularly strong or distinctive patterns, which could suggest that these timbral features are not as salient in this song as other characteristics such as the use of ambient textures and electronic instrumentation.

Given that "Blade Runner Blues" is part of a playlist of iconic soundtracks, it is worth noting that the song was composed by Vangelis for the soundtrack of the 1982 film "Blade Runner", which is considered a landmark of science fiction cinema. The use of electronic instruments and atmospheric textures in the song is consistent with the film's dystopian and futuristic themes, while the melancholic and introspective mood of the music reflects the emotional depth and complexity of the film's characters and themes.

Overall, the chromagram and cepstrogram plots provide valuable insights into the melodic and timbral characteristics of "Blade Runner Blues", which can be used to shed light on the song's structure, style, and meaning, as well as its cultural and historical significance as part of the iconic "Blade Runner" soundtrack.


### Chroma Values Soundstrack outlier

```{r}

# get playlist data
iconic_soundtracks <- get_playlist_audio_features("","37i9dQZF1DX1tz6EDao8it")
classical_essentials <- get_playlist_audio_features("","37i9dQZF1DWWEJlAGA9gs0")

# extract chroma values
get_chroma <- function(track.id) {
  audio_analysis <- get_track_audio_analysis(track.id)
  chroma <- audio_analysis$segments %>%
    select(start, pitches) %>%
    unnest(pitches) %>%
    mutate(pitch_class = rep(c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"), length.out = length(pitches)),
           intensity = as.numeric(pitches)) %>%
    select(-pitches) %>%
    spread(pitch_class, intensity, fill = 0)
  
  return(chroma)
}


# get chroma data frames for all tracks in iconic_soundtracks playlist
iconic_soundtracks_chroma <- map(iconic_soundtracks$track.id, get_chroma)

iconic_soundtracks_chroma <- map2(iconic_soundtracks_chroma, iconic_soundtracks$track.id, ~ .x %>% mutate(track_id = .y))

iconic_soundtracks_chroma <- bind_rows(iconic_soundtracks_chroma)

chroma_data <- iconic_soundtracks_chroma %>%
  filter(track_id == "575blCgesVtCu0HEYaIcas")

chroma_data <- chroma_data %>%
  select(-track_id)

chroma_data <- chroma_data %>%
  gather(note, value, -start)

chromagram <- chroma_data %>%
  group_by(note) %>%
  summarise(chroma = sum(value))



plotly_chroma_feature <- chromagram %>%
  plot_ly(x = ~note, y = ~chroma, type = "bar",
          text = ~paste0(round(chroma * 100, 1), "%"),
          hoverinfo = "text",
          marker = list(color = "rgba(55, 128, 191, 0.7)",
                        line = list(color = "rgba(55, 128, 191, 1.0)",
                                    width = 1))) %>%
  layout(xaxis = list(title = "Note"),
         yaxis = list(title = "Chroma value"),
         title = list(text = "Chroma feature Blade Runner Blues"))

plotly_chroma_feature


```

---

These plots show the chroma features for 'Blade Runner Blues' from the "iconic_soundtracks" Spotify playlist and ... 

The chroma feature is a way of representing the tonal content of an audio signal. It is based on the 12 different pitches in a chromatic scale (C, C#, D, D#, E, F, F#, G, G#, A, A#, B), and for each pitch it calculates a value that represents the amount of energy in the audio signal that corresponds to that pitch.

In this plot, the x-axis shows the 12 different pitches (notes) in the chromatic scale, and the y-axis shows the corresponding chroma value for each note. The height of each bar represents the amount of energy in the audio signal that corresponds to that note, and the color of each bar indicates the magnitude of the chroma value (with darker colors indicating higher values). The hover text displays the exact percentage of energy in the audio signal that corresponds to each note.

In summary, this plot shows the relative distribution of energy across the 12 different pitches in the audio signal for a specific track.

### Chroma Values Classical outlier 

```{r}

# extract chroma values
get_chroma <- function(track.id) {
  audio_analysis <- get_track_audio_analysis(track.id)
  chroma <- audio_analysis$segments %>%
    select(start, pitches) %>%
    unnest(pitches) %>%
    mutate(pitch_class = rep(c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"), length.out = length(pitches)),
           intensity = as.numeric(pitches)) %>%
    select(-pitches) %>%
    spread(pitch_class, intensity, fill = 0)
  
  return(chroma)
}

# get chroma data frames for all tracks in iconic_soundtracks playlist

classical_essentials_chroma <- map(classical_essentials$track.id, get_chroma)

classical_essentials_chroma <- map2(classical_essentials_chroma, classical_essentials$track.id, ~ .x %>% mutate(track_id = .y))

classical_essentials_chroma <- bind_rows(classical_essentials_chroma)


chroma_data <- classical_essentials_chroma %>%
  filter(track_id == "5fdp9rXfEixCGLM1Og4EN1")

chroma_data <- chroma_data %>%
  select(-track_id)

chroma_data <- chroma_data %>%
  gather(note, value, -start)

chromagram <- chroma_data %>%
  group_by(note) %>%
  summarise(chroma = sum(value))


plotly_chroma_feature <- chromagram %>%
  plot_ly(x = ~note, y = ~chroma, type = "bar",
          text = ~paste0(round(chroma * 100, 1), "%"),
          hoverinfo = "text",
          marker = list(color = "rgba(55, 128, 191, 0.7)",
                        line = list(color = "rgba(55, 128, 191, 1.0)",
                                    width = 1))) %>%
  layout(xaxis = list(title = "Note"),
         yaxis = list(title = "Chroma value"),
         title = list(text = "Chroma feature for track Gnossienne No. 1"))

plotly_chroma_feature

```

---

These plots show the chroma features for 'Blade Runner Blues' from the "iconic_soundtracks" Spotify playlist and ... 

The chroma feature is a way of representing the tonal content of an audio signal. It is based on the 12 different pitches in a chromatic scale (C, C#, D, D#, E, F, F#, G, G#, A, A#, B), and for each pitch it calculates a value that represents the amount of energy in the audio signal that corresponds to that pitch.

In this plot, the x-axis shows the 12 different pitches (notes) in the chromatic scale, and the y-axis shows the corresponding chroma value for each note. The height of each bar represents the amount of energy in the audio signal that corresponds to that note, and the color of each bar indicates the magnitude of the chroma value (with darker colors indicating higher values). The hover text displays the exact percentage of energy in the audio signal that corresponds to each note.

In summary, this plot shows the relative distribution of energy across the 12 different pitches in the audio signal for a specific track.

 
Introduction {data-icon="fa-file-text"}
=======================================================

### Difference between classical music and movie soundtracks

For my portfolio, I have chosen a corpus that compares classical music with film soundtracks. The corpus will include track from the “Classical Essential” and “Iconic Soundtracks” playlists on Spotify. I am interested in this because both classical music and film soundtracks can evoke emotions in listeners, but the audiences of both can be very different, which is why I want to see what differentiates the two.

In my corpus I will compare classical compositions with film soundtracks. Within these groups, there are various natural subgroups such as individual composers, specific movies, and musical genres. I expect to find differences in instrumentation and production between the two groups, as well as differences between individual composers and genres. However, I also anticipate finding commonalities in melody, harmony, and musical structure.

The tracks in my corpus are representative of the groups I want to compare, but there are probably some recordings missing or variations that could affect the analysis. For example, there may be differences between the live and studio versions of a classical piece that are not reflected in the corpus. I will keep this in mind when the data.

One atypical track in my corpus is "Hedwig's Theme" by John Williams, which for most of the track uses only the celesta and a unique melody. A typical track is "Für Elise" by Ludwig van Beethoven, which is a well-known classical piece with a recognizable melody.
